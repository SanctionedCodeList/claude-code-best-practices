# December 2025 - Buckle Up

Hey team,

It's been about a month since my last update, and I'll be honest with you: writing these has gotten harder. Not because there's less to say—quite the opposite. The challenge is that the landscape shifts so quickly that by the time I finish a sentence, I'm worried it's already outdated. But that's exactly why I need to write this one.

**Buckle up.** I mean that literally. What I'm about to share isn't speculation or hype—it's data, and the data is telling us something profound about 2026.

## The Trend Line Isn't Slowing Down. It's Accelerating.

Remember that METR graph I shared last month showing AI task completion capability doubling every 7 months? I need to update that.

According to [METR's latest analysis](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/), the trend has *accelerated*. In 2024-2025, time horizons doubled every **4 months**, down from every 7 months over 2019-2025. And here's what's even more striking: models like o3, Grok 4, GPT-5, and GPT-5.1-Codex-Max are all landing **ahead** of the predicted curve—reaching expected task lengths 1-3 months earlier than forecast.

Let me put that in concrete terms:
- **2022 (ChatGPT/GPT-3.5):** 36 seconds of autonomous task completion
- **Today (GPT-5.1-Codex-Max):** 2 hours and 42 minutes

If the accelerated trend continues, we should have agents capable of **full day autonomy by late 2026** and **week-long projects by 2027**. If it *continues* to accelerate—which the data suggests it might—those timelines compress further.

[Epoch AI's research](https://epoch.ai/data-insights/ai-capabilities-progress-has-sped-up) confirms this isn't a METR-specific finding. Their Capabilities Index shows the rate of frontier improvement **nearly doubled**—from about 8 points/year before April 2024 to 15 points/year after. They attribute this to the rise of reasoning models and increased focus on reinforcement learning.

## From Winning Competitions to Making Discoveries

Here's something that got lost in the holiday news cycle, and I think it's one of the most significant developments of the year.

In July 2025, [Gemini with Deep Think achieved gold-medal level at the International Mathematical Olympiad](https://deepmind.google/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/)—solving five of six problems perfectly, scoring 35 out of 42 points. OpenAI achieved the exact same score. IMO President Prof. Dr. Gregor Dolinar called the solutions "astonishing in many respects."

For context: just one year earlier, these systems achieved *silver* medal level (28 points). The year before that, they couldn't compete at all.

But here's what matters more than the medal: **AI has crossed the threshold from solving known problems to contributing to unknown frontiers.**

### Novel Mathematical Discoveries

[AlphaEvolve](https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/), DeepMind's evolutionary coding agent, discovered a new construction for the finite field Kakeya conjecture. That construction was good enough to inspire **Terence Tao**—the Fields Medalist, arguably the world's greatest living mathematician—to write a new theoretical paper based on the insight.

Let me say that again: an AI system produced a result that a Fields Medalist found worthy of building upon.

AlphaEvolve also improved the lower bound for the [kissing number problem](https://en.wikipedia.org/wiki/Kissing_number) in 11 dimensions from 592. When tested on 50 open mathematical problems, it matched state-of-the-art algorithms 75% of the time and **discovered improved solutions 20% of the time**.

Meanwhile, [AlphaProof proved a PhD student's lemma](https://www.nature.com/articles/d41586-025-03585-5) in under a minute—a lemma the student and their collaborator had been stuck on for weeks. It then disproved another lemma, exposing a bug in a definition. This is what mathematical collaboration looks like now.

### Scientific Discoveries Beyond Math

The pattern extends beyond mathematics:

**Drug Discovery:** Google's [AI co-scientist](https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/)—a multi-agent system built on Gemini 2.0—helped Stanford researchers identify drugs that could be repurposed to treat liver fibrosis. At Imperial College London, researchers working on antimicrobial resistance found it produced **in days the same hypothesis their team took years to develop**.

**Biology:** [FutureHouse](https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630) demonstrated a multi-agent workflow that identified a new therapeutic candidate for dry age-related macular degeneration—a leading cause of irreversible blindness.

**Materials Science:** Microsoft's [MatterGen](https://news.microsoft.com/source/features/ai/10-scientific-breakthroughs-from-microsoft-researchers/) generates novel materials from text prompts. Berkeley Lab's [A-Lab](https://newscenter.lbl.gov/2025/09/04/how-berkeley-lab-is-using-ai-and-automation-to-speed-up-science-and-discovery/) combines AI algorithms with robotics to autonomously propose, synthesize, and test new compounds.

**Protein Science:** [AlphaFold](https://deepmind.google/blog/alphafold-five-years-of-impact/), which won the Nobel Prize in Chemistry last year, now has a database of over 200 million predicted protein structures used by 3.5 million researchers in 190 countries. Scientists recently used it to discover a protein complex essential for allowing sperm to fertilize an egg—a fundamental biological mechanism we didn't understand before.

### Why This Matters for Our Profession

I'm belaboring this point because I need you to understand: this isn't "AI getting better at tests." This is **AI beginning to do real research**.

If AI can contribute novel insights to mathematics and drug discovery, it can contribute novel insights to legal analysis. The question isn't *whether* this capability transfers to law—it's *when* and *how well*.

The firms that figure this out first won't just be more efficient. They'll be offering something qualitatively different.

## We're Watching the Early Stages of Recursive Self-Improvement

I want to be careful here, because this term gets thrown around loosely. But I think we need to name what's happening.

[Recursive self-improvement](https://en.wikipedia.org/wiki/Recursive_self-improvement) (RSI) is when an AI system enhances its own capabilities, and those enhancements make it better at further enhancing itself. It's the mechanism behind most serious "takeoff" scenarios.

In May 2025, Google DeepMind unveiled [AlphaEvolve](https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/)—an evolutionary coding agent that uses an LLM to design and optimize algorithms. It repeatedly mutates and combines existing algorithms to generate improved candidates. Critically, it can optimize components of *itself*.

Meta has assembled what they're calling a "superintelligence research team," offering signing bonuses up to $100 million to poach researchers from OpenAI, Anthropic, and Google. Mark Zuckerberg has publicly stated his goal is for Meta to "lead the world into the age of AI superintelligence."

This isn't theoretical anymore. The infrastructure for RSI is being built in the open. We're watching it happen.

## What Does This Mean for Law?

Here's where I need to get specific, because I know many of you think this is primarily a tech industry story. It's not.

The [American Bar Association's 2025 report](https://www.americanbar.org/groups/law_practice/resources/law-technology-today/2025/the-legal-industry-report-2025/) shows AI use among legal professionals increased **315% from 2023 to 2024**. About 79% of law firms have now integrated AI tools into their workflows.

But here's the critical insight: **only a fraction have actually transformed their operations**. Most are using AI for incremental improvements—faster document review, quicker research. That's the equivalent of using a car to store groceries.

The firms that are actually paying attention? They're seeing numbers like this: a complaint response system that reduced associate time from **16 hours to 3-4 minutes**. That's not a typo. That's a 100x+ productivity gain.

And remember what I wrote last month about the [McKinsey State of AI 2025](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai)? The roughly 6% of organizations seeing 5%+ EBIT impact from AI aren't the ones who adopted more tools. They're the ones who **fundamentally rethought how work gets done**.

## Why I'm Writing This: Claude Code and Opus 4.5

I need to tell you about what I've been using, because I think most of you have no idea what's possible right now.

I've been working extensively with Claude Code—Anthropic's command-line coding assistant—powered by Opus 4.5 (the model you're reading this from, actually). Originally built for software developers, it turns out to be transformatively useful for legal work.

Here's what I mean:

**Research and synthesis**: I can point it at a complex regulatory question, and it will search databases, read documents, synthesize findings, and produce a memo-quality analysis. Not a draft I need to rewrite—an actual analysis I need to verify and refine.

**Document automation**: It doesn't just fill in templates. It understands context, reasons about edge cases, and asks clarifying questions when requirements are ambiguous.

**Multi-step projects**: This is the key differentiator. Unlike earlier tools, this generation of AI can hold context across extended work sessions. It can remember what we discussed yesterday and build on it today. It can manage multi-file projects, track dependencies, and maintain consistency across documents.

The reason I'm highlighting tools "originally made for coding" is that coders have been the early adopters, the guinea pigs, the ones building muscle memory with these systems. [Andrej Karpathy just posted](https://x.com/karpathy/status/2004607146781278521) about feeling "behind" despite being one of the most accomplished AI researchers alive—because the tooling is evolving so fast that even experts struggle to keep up.

That post got 4.3 million views in hours. It resonated because it captured something true: we're all scrambling to figure out how to work with these "alien tools," as Karpathy called them. The legal profession isn't exempt from this scramble—we're just starting later.

## What's Coming in 2026

Based on the trend data, here's what I expect:

**Q1 2026**: Agents capable of 4-6 hour autonomous work sessions become standard. Law firms using these tools will see another step-change in productivity.

**Q2-Q3 2026**: First wave of "AI-native" legal practices—[firms built from the ground up around AI workflows](https://www.anytimeai.ai/blog/the-future-of-law-rise-of-ai-native-firms-in-2025/)—will start winning significant market share. Traditional firms will face pricing pressure they've never experienced.

**Q4 2026**: The billable hour model will face existential pressure. When AI can do 16 hours of work in 4 minutes, billing by the hour becomes absurd. [Value-based pricing](https://clp.law.harvard.edu/knowledge-hub/insights/the-impact-of-artificial-intelligence-on-law-law-firms-business-models/) won't be optional anymore.

**Throughout 2026**: The ABA's "technological competence" requirement will start being enforced more seriously. Lawyers who can't effectively supervise and verify AI output will face malpractice exposure.

## What Should You Do?

I'm a big fan of "show not tell" and "lead by example," so let me tell you what I'm doing:

1. **Spending real time with the tools.** Not reading about them—using them. Building muscle memory. Learning when they're reliable and when they're not.

2. **Rethinking workflows from first principles.** Not "how do I use AI to help with document review?" but "given that AI exists, how should document review work?"

3. **Building verification skills.** The bottleneck is shifting from production to verification. The lawyers who thrive will be the ones who can quickly and accurately assess AI output.

4. **Preparing for the business model shift.** If 80% of your revenue comes from billable hours, and productivity is about to increase 10-100x, you need a new model. Now, not later.

## Final Thought

I want to be clear about something: I'm not predicting doom, and I'm not predicting utopia. I'm observing trends and sharing what the data shows.

What the data shows is that we're entering a period of profound transformation. The [Takeoff Speeds model](https://www.lesswrong.com/posts/jLEcddwp4RBTpPHHq/takeoff-speeds-update-crunch-time-1), updated with recent Epoch AI data, now predicts AI capable of full economic automation around 2030—a full decade earlier than previous estimates.

Whether that's good or bad depends largely on how we prepare. And preparation starts with awareness.

So: buckle up. 2026 is going to be a ride.

Happy holidays, and I'll see you on the other side of New Year's.

— Parker

---

**Sources:**

*AI Progress & Acceleration:*
- [METR: Measuring AI Ability to Complete Long Tasks](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/)
- [Epoch AI: AI Capabilities Progress Has Sped Up](https://epoch.ai/data-insights/ai-capabilities-progress-has-sped-up)
- [LessWrong: Takeoff Speeds Update](https://www.lesswrong.com/posts/jLEcddwp4RBTpPHHq/takeoff-speeds-update-crunch-time-1)

*AI Research Breakthroughs:*
- [Gemini Deep Think Achieves IMO Gold Medal](https://deepmind.google/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/)
- [AlphaEvolve: Evolutionary Coding Agent](https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/)
- [Nature: Mathematicians Put AlphaProof to the Test](https://www.nature.com/articles/d41586-025-03585-5)
- [Google: AI Co-Scientist](https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/)
- [MIT: FutureHouse Accelerates Scientific Discovery](https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630)
- [Microsoft: 10 Scientific Breakthroughs](https://news.microsoft.com/source/features/ai/10-scientific-breakthroughs-from-microsoft-researchers/)
- [Berkeley Lab: AI and Automation in Science](https://newscenter.lbl.gov/2025/09/04/how-berkeley-lab-is-using-ai-and-automation-to-speed-up-science-and-discovery/)
- [AlphaFold: Five Years of Impact](https://deepmind.google/blog/alphafold-five-years-of-impact/)

*Legal Profession:*
- [American Bar Association: The Legal Industry Report 2025](https://www.americanbar.org/groups/law_practice/resources/law-technology-today/2025/the-legal-industry-report-2025/)
- [Harvard Law: Impact of AI on Law Firms' Business Models](https://clp.law.harvard.edu/knowledge-hub/insights/the-impact-of-artificial-intelligence-on-law-law-firms-business-models/)
- [The Future of Law: Rise of AI-Native Firms](https://www.anytimeai.ai/blog/the-future-of-law-rise-of-ai-native-firms-in-2025/)

*Other:*
- [Karpathy on X (Dec 26, 2025)](https://x.com/karpathy/status/2004607146781278521)
